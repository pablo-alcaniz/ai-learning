{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a177967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from pyHorses3D import Horses3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8791a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de hiperparametros:\n",
    "\n",
    "batch_size = 1024 #tamaño de lotes de entrenamiento\n",
    "\n",
    "hidden_dim_1 = 20 #tamaño de la capa 1\n",
    "hidden_dim_2 = 10 #tamaño de la capa 2\n",
    "\n",
    "lr = 0.01 #tasa de aprendizaje\n",
    "n_epochs = 10 #reiteraciones sobre la base de datos de entrenamiento completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6329d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay que tener en cuenta que por como funciona la red no le tenemos que pasar el vector de 28*28, le tenemos que pasar la imagen y la red\n",
    "# se encarga de dejarla en forma de vector.\n",
    "\n",
    "class MNIST_data(Dataset):\n",
    "    def __init__(self, path_to_data: str, train: bool = True, mmap = True, dtype=torch.float32):\n",
    "        self.dtype = dtype\n",
    "        if train:\n",
    "            self.DATA = pd.read_csv(path_to_data)\n",
    "            self.DATA = self.DATA.fillna(0)\n",
    "            self.DATA = np.array(self.DATA)\n",
    "            self.LABELS = self.DATA[:,0]\n",
    "            self.LABELS = np.array(self.LABELS)\n",
    "            self.IMAGES_UNPROC = self.DATA[:,1:]/255\n",
    "            self.IMAGES_PROC = np.empty(shape=[self.IMAGES_UNPROC.shape[0],int(np.sqrt(self.IMAGES_UNPROC.shape[1])),int(np.sqrt(self.IMAGES_UNPROC.shape[1]))])\n",
    "            for i in range(self.IMAGES_UNPROC.shape[0]):\n",
    "                for j in range(28):\n",
    "                    for k in range(28):\n",
    "                        self.IMAGES_PROC[i,j,k] = self.IMAGES_UNPROC[i,28*j+k]\n",
    "    def __len__(self):\n",
    "        return self.DATA.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        LABEL = self.LABELS[index]\n",
    "        LABEL = torch.tensor(LABEL).to(self.dtype)\n",
    "        IMAGE = self.IMAGES_PROC[index,:,:]\n",
    "        IMAGE = torch.from_numpy(IMAGE).to(self.dtype)\n",
    "        return IMAGE, LABEL        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d589c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga del dataset:\n",
    "\n",
    "train_dataset = MNIST_data(\"data/mnist_train.csv\")\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fef932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos: \n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad00b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Comprobacion del dispositivo de ejecucion: \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad06ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de la arquitectura modelo:\n",
    "\n",
    "encoder_arch = nn.Sequential(\n",
    "    nn.Flatten(), #tranforma el array de entrada (28,28) en un tensor (28*28,1)\n",
    "    nn.Linear(28*28, hidden_dim_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178528b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion del modelo:\n",
    "\n",
    "class MNIST_classifier(nn.Module):\n",
    "    def __init__(self, encoder_arch):\n",
    "        super(MNIST_classifier, self).__init__()\n",
    "        self.forward_arch = encoder_arch\n",
    "    def forward(self, data):\n",
    "        out = self.forward_arch(data)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd048b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializacion del modelo:\n",
    "\n",
    "clasificador = MNIST_classifier(encoder_arch=encoder_arch).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d39b2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de pérdida:\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1759a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizador: \n",
    "optimizer = optim.Adam(clasificador.parameters(), lr = lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b4772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de evaluacion del modelo sobre toda la base de datos de evaluzacion\n",
    "\n",
    "def model_eval(model, device, test_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for image, label in test_data:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        prediction = model(image)\n",
    "        if int(torch.argmax(prediction)) == int(label):\n",
    "            correct = correct + 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84920505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de entrenamiento: \n",
    "\n",
    "def model_train(model, train_data, test_data, n_epochs, optimizer, loss_function):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        #correct = model_eval(model, device, test_data)\n",
    "        #print(f\"Epoch {epoch} ----> Correct guesses: {correct}/{len(test_data)}\")\n",
    "        model.train()\n",
    "        for batch_id, (image, label) in enumerate(train_data):\n",
    "            image, label = image.to(device), label.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            model_output = model(image)\n",
    "            loss = loss_function(model_output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_id % 1000 == 0:\n",
    "                print(f\"Epoch {epoch} [{batch_id * len(image)}/{len(train_data.dataset)}] Loss: {loss.item():6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c9df623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0/59999] Loss: 2.301937\n",
      "Epoch 1 [0/59999] Loss: 1.573147\n",
      "Epoch 2 [0/59999] Loss: 1.551011\n",
      "Epoch 3 [0/59999] Loss: 1.533352\n",
      "Epoch 4 [0/59999] Loss: 1.527844\n",
      "Epoch 5 [0/59999] Loss: 1.517977\n",
      "Epoch 6 [0/59999] Loss: 1.513807\n",
      "Epoch 7 [0/59999] Loss: 1.520608\n",
      "Epoch 8 [0/59999] Loss: 1.513216\n",
      "Epoch 9 [0/59999] Loss: 1.507356\n"
     ]
    }
   ],
   "source": [
    "model_train(clasificador,train_data,test_data, n_epochs,optimizer,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8165c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct guesses: 9446/10000, 94.46%\n"
     ]
    }
   ],
   "source": [
    "correct = model_eval(clasificador, device, test_data)\n",
    "print(f\"Correct guesses: {correct}/{len(test_data)}, {correct/len(test_data)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef66e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_classifier(\n",
       "  (forward_arch): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=20, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funcion para resetear el modelo\n",
    "\n",
    "def reset_weights(m):\n",
    "    if hasattr(m, \"reset_parameters\"):\n",
    "        m.reset_parameters()\n",
    "\n",
    "clasificador.apply(reset_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-learning (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
